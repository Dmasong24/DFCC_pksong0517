{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6rERTCDf58DKdJMXeK84n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dmasong24/DFCC_pksong0517/blob/park/DFCC_eval_Local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvqBqKxtZeJh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import librosa\n",
        "#!pip install tensorflow\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"DFCC_pksong0517.keras\")   # 만들어둔 model 가져오기\n",
        "\n",
        "# test_label 오름차순 정렬을 위한 숫자 부분 추출 함수\n",
        "def extract_number_from_test_label(test_label):\n",
        "    match = re.search(r'\\d+', test_label)\n",
        "    if match:\n",
        "        return match.group(0)\n",
        "    return None\n",
        "\n",
        "# test_labels 불러오기\n",
        "test_label = pd.read_table('test_label.txt', sep='- -', header=None, names=['voice_name','label'])\n",
        "test_label['voice_number'] = test_label['voice_name'].apply(extract_number_from_test_label)\n",
        "test_label.sort_values('voice_number', inplace=True)\n",
        "le = LabelEncoder()\n",
        "test_labels = le.fit_transform(test_label['label'])\n",
        "\n",
        "# test_wav 파일 가져오기\n",
        "def test_dataset():\n",
        "    folder = \"test\"\n",
        "    dataset = []\n",
        "    for file in sorted(os.listdir(folder)):\n",
        "        if 'wav' in file:\n",
        "            abs_file_path = os.path.join(folder,file)\n",
        "            data, sr = librosa.load(abs_file_path, sr = 16000)   # data = 진폭값, sr = sample_rate = 16,000(초당 샘플 갯수)\n",
        "            dataset.append([data, file])\n",
        "\n",
        "    print(\"test_Dataset 생성 완료\")\n",
        "    return pd.DataFrame(dataset,columns=['data', 'file'])\n",
        "\n",
        "test_wav = test_dataset()\n",
        "\n",
        "# train & test 때 사용했던 max_length(=111872)로 test_wav Padding\n",
        "def set_length_with_padding(data, max_length):\n",
        "    result = []\n",
        "    for i in data:\n",
        "        padded_audio = librosa.util.fix_length(i, size=max_length)\n",
        "        result.append(padded_audio)\n",
        "    result = np.array(result)\n",
        "    return result\n",
        "\n",
        "test_x = np.array(test_wav.data)\n",
        "test_x = set_length_with_padding(test_x, 111872)\n",
        "print(\"padding 완료\")\n",
        "\n",
        "# MFCC 특징 추출하기\n",
        "def preprocess_dataset(data):\n",
        "    mfccs = []\n",
        "    for i in data:\n",
        "        extracted_features = librosa.feature.mfcc(y=i,sr=16000,n_mfcc=40)\n",
        "        mfccs.append(extracted_features)\n",
        "\n",
        "    return mfccs\n",
        "\n",
        "test_mfccs = preprocess_dataset(test_x)\n",
        "test_mfccs = np.array(test_mfccs)\n",
        "test_mfccs = test_mfccs.reshape(-1, test_mfccs.shape[1], test_mfccs.shape[2], 1)\n",
        "\n",
        "# 테스트 레이블 전처리 함수\n",
        "def extract_number_from_test_label(name):\n",
        "    \"\"\"파일명에서 숫자 추출 (예: KDF_E_1004 → 1004)\"\"\"\n",
        "    return int(name.split('_')[-1].split('.')[0])\n",
        "\n",
        "# 테스트 레이블 불러오기\n",
        "test_label = pd.read_table(\n",
        "    'label/test_label.txt',\n",
        "    sep='- -',\n",
        "    engine='python',\n",
        "    header=None,\n",
        "    names=['voice_name','label']\n",
        ")\n",
        "\n",
        "# 파일명 전처리 (YSG 등 프리픽스 제거)\n",
        "test_label['voice_name'] = test_label['voice_name'].str[4:].str.strip()\n",
        "test_label['voice_number'] = test_label['voice_name'].apply(extract_number_from_test_label)\n",
        "test_label.sort_values('voice_number', inplace=True)\n",
        "\n",
        "# 레이블 인코딩\n",
        "le = LabelEncoder()\n",
        "test_labels = le.fit_transform(test_label['label'])\n",
        "\n",
        "# 테스트 데이터 경로 설정\n",
        "test_data_path = 'test'\n",
        "\n",
        "# 데이터 저장 리스트 초기화\n",
        "test_file_names = []\n",
        "test_x = []\n",
        "test_y = []\n",
        "\n",
        "# 음성 데이터 처리 파이프라인\n",
        "for idx, row in test_label.iterrows():\n",
        "    file_name = row['voice_name']\n",
        "    label_encoded = test_labels[idx]  # 인코딩된 라벨 사용[6]\n",
        "\n",
        "    # 실제 오디오 파일 경로 생성\n",
        "    wav_path = os.path.join(test_data_path, file_name)\n",
        "\n",
        "    # 파일 존재 여부 확인 (검색 결과[5][9] 반영)\n",
        "    if not os.path.exists(wav_path):\n",
        "        print(f\"경고: {wav_path} 파일 없음\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # 오디오 처리 (메모리 엔트리[10]의 CNN 입력 요구사항 반영)\n",
        "        y, sr = librosa.load(wav_path, sr=16000)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
        "        mfcc_delta = librosa.feature.delta(mfcc)\n",
        "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
        "\n",
        "        mfcc_combined = np.concatenate((mfcc, mfcc_delta, mfcc_delta2), axis=0)\n",
        "        mfcc_mean = np.mean(mfcc_combined, axis=1)\n",
        "\n",
        "        test_x.append(mfcc_mean)\n",
        "        test_y.append(label_encoded)\n",
        "        test_file_names.append(file_name)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"{file_name} 처리 실패: {str(e)}\")\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# 리스트를 numpy 배열로 변환\n",
        "X_test = np.array(test_x)\n",
        "\n",
        "# 라벨 인코딩 (0: fake, 1: real)\n",
        "le = LabelEncoder()\n",
        "y_test = le.fit_transform(test_y)\n",
        "\n",
        "# 예: 파일 이름과 데이터, 라벨을 묶어서 정렬\n",
        "combined = list(zip(test_file_names, test_mfccs, test_labels))\n",
        "combined.sort(key=lambda x: x[0])  # 파일 이름 기준 정렬\n",
        "\n",
        "# 다시 분리\n",
        "sorted_file_names, sorted_mfccs, sorted_labels = zip(*combined)\n",
        "\n",
        "# numpy 배열로 변환\n",
        "sorted_mfccs = np.array(sorted_mfccs)\n",
        "sorted_labels = np.array(sorted_labels)\n",
        "\n",
        "y_pred = model.predict(sorted_mfccs)\n",
        "y_pred_probs = y_pred.flatten()\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "precision, recall, thresholds = precision_recall_curve(sorted_labels, y_pred_probs)\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
        "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
        "\n",
        "y_pred_classes = (y_pred_probs > optimal_threshold).astype(int)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc = accuracy_score(sorted_labels, y_pred_classes)\n",
        "print(\"정렬 후 정확도:\", acc)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "# 혼동 행렬(Confusion Matrix) 시각화\n",
        "cm = confusion_matrix(sorted_labels, y_pred_classes)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# label을 sort시킴\n",
        "# 파일 읽기\n",
        "with open('label/test_label.txt', 'r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# 번호 추출 함수\n",
        "def extract_number(line):\n",
        "    # 예시: YSG KDF_E_1004.wav - - Real\n",
        "    m = re.search(r'_(\\d+)\\.wav', line)\n",
        "    return int(m.group(1)) if m else float('inf')\n",
        "\n",
        "# 정렬\n",
        "sorted_lines = sorted(lines, key=extract_number)\n",
        "\n",
        "# 저장\n",
        "with open('label/test_label_sorted.txt', 'w', encoding='utf-8') as f:\n",
        "    f.writelines(sorted_lines)\n",
        "\n",
        "# test_label_sorted.txt 기준으로 예측 파일 생성\n",
        "sorted_test_label = pd.read_table(\n",
        "    'label/test_label_sorted.txt',\n",
        "    sep='- -',\n",
        "    engine='python',\n",
        "    header=None,\n",
        "    names=['voice_name','label']\n",
        ")\n",
        "\n",
        "#test_result 또한 sort시킴\n",
        "with open('pksong0517_test_result_sorted.txt', 'w') as f:\n",
        "    for idx, row in sorted_test_label.iterrows():\n",
        "        # 프리픽스 제거된 파일명 사용\n",
        "        file_name = row['voice_name'].split(' ', 1)[1].strip()\n",
        "        pred_label = 'Real' if y_pred_classes[idx] == 1 else 'Fake'\n",
        "        f.write(f\"{file_name} {pred_label}\\n\")\n",
        "\n",
        "#sort된 label을 통해 eval.pl 실행\n",
        "!perl eval.pl pksong0517_test_result_sorted.txt test_label_sorted.txt"
      ]
    }
  ]
}